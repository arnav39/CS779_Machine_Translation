{"cells":[{"cell_type":"markdown","metadata":{},"source":["# CS779 Machine Translation\n","\n","- hindi to english \n","\n","- trying to process a batch at once"]},{"cell_type":"markdown","metadata":{},"source":["## Importing libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:31:09.965304Z","iopub.status.busy":"2023-04-12T18:31:09.964793Z","iopub.status.idle":"2023-04-12T18:31:45.195177Z","shell.execute_reply":"2023-04-12T18:31:45.193739Z","shell.execute_reply.started":"2023-04-12T18:31:09.965269Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}],"source":["!pip install indic-nlp-library --quiet\n","!python -m spacy download en_core_web_sm --quiet"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:31:52.090924Z","iopub.status.busy":"2023-04-12T18:31:52.090173Z","iopub.status.idle":"2023-04-12T18:32:05.579618Z","shell.execute_reply":"2023-04-12T18:32:05.578493Z","shell.execute_reply.started":"2023-04-12T18:31:52.090882Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn \n","import torch.optim as optim \n","import numpy as np\n","import torch.nn.functional as F\n","import spacy\n","import os\n","from tqdm.notebook import tqdm\n","import sys\n","from indicnlp.tokenize import indic_tokenize\n","from indicnlp.normalize import indic_normalize\n","import pickle\n","import random\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:13:05.738906Z","iopub.status.busy":"2023-04-12T23:13:05.737772Z","iopub.status.idle":"2023-04-12T23:13:05.744694Z","shell.execute_reply":"2023-04-12T23:13:05.743505Z","shell.execute_reply.started":"2023-04-12T23:13:05.738856Z"},"trusted":true},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:32:05.582668Z","iopub.status.busy":"2023-04-12T18:32:05.581759Z","iopub.status.idle":"2023-04-12T18:32:05.589046Z","shell.execute_reply":"2023-04-12T18:32:05.587847Z","shell.execute_reply.started":"2023-04-12T18:32:05.582627Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["device = cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"device = {device}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:32:05.591181Z","iopub.status.busy":"2023-04-12T18:32:05.590599Z","iopub.status.idle":"2023-04-12T18:32:05.864376Z","shell.execute_reply":"2023-04-12T18:32:05.863100Z","shell.execute_reply.started":"2023-04-12T18:32:05.591141Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'>\n","140000\n","<class 'list'>\n","140000\n"]}],"source":["with open('/kaggle/input/cs779-mt-hindi-2-english/inp_sent.pkl', 'rb') as f: \n","  output_sent_list = pickle.load(f) # output is english\n","\n","with open('/kaggle/input/cs779-mt-hindi-2-english/out_sent.pkl', 'rb') as f: \n","  input_sent_list = pickle.load(f) # input is hindi\n","\n","print(type(input_sent_list))\n","print(len(input_sent_list))\n","\n","print(type(output_sent_list))\n","print(len(output_sent_list))"]},{"cell_type":"markdown","metadata":{},"source":["## Vocab classes"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:32:05.868377Z","iopub.status.busy":"2023-04-12T18:32:05.866673Z","iopub.status.idle":"2023-04-12T18:32:05.877167Z","shell.execute_reply":"2023-04-12T18:32:05.876061Z","shell.execute_reply.started":"2023-04-12T18:32:05.868334Z"},"trusted":true},"outputs":[],"source":["class Lang():\n","\n","  def __init__(self, name, spacy_tokenizer):\n","    self.name = name\n","    self.word2index = {\"<SOS>\":0, '<EOS>': 1, \"<UNK>\": 2, '<PAD>': 3}\n","    self.index2word = {0: \"<SOS>\", 1: \"<EOS>\", 2: \"<UNK>\", 3: '<PAD>'}\n","    self.word2count = {}\n","    self.n_words = 4\n","    self.tokenizer = spacy_tokenizer\n","\n","  def add_word(self, word):\n","    if word not in self.word2index:\n","      self.word2index[word] = self.n_words\n","      self.word2count[word] = 1\n","      self.index2word[self.n_words] = word\n","      self.n_words += 1\n","\n","    else:\n","      self.word2count[word] += 1\n","\n","  def add_sentence(self, sentence):\n","    tokens = self.tokenize_sentence(sentence)\n","    for token in tokens: \n","      self.add_word(token)\n","\n","  def tokenize_sentence(self, sentence):\n","    tokens = [token.text for token in self.tokenizer(sentence.lower())]\n","    return tokens\n","\n","  def __len__(self):\n","    return self.n_words"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:32:05.879599Z","iopub.status.busy":"2023-04-12T18:32:05.878632Z","iopub.status.idle":"2023-04-12T18:32:05.896883Z","shell.execute_reply":"2023-04-12T18:32:05.895864Z","shell.execute_reply.started":"2023-04-12T18:32:05.879557Z"},"trusted":true},"outputs":[],"source":["class Hindi_lang():\n","\n","  def __init__(self, name):\n","    self.name = name\n","    self.word2index = {\"<SOS>\":0, '<EOS>': 1, \"<UNK>\": 2, '<PAD>': 3}\n","    self.index2word = {0: \"<SOS>\", 1: \"<EOS>\", 2: \"<UNK>\", 3: '<PAD>'}\n","    self.word2count = {}\n","    self.n_words = 4\n","    self.normalizer = indic_normalize.DevanagariNormalizer(lang='hi', remove_nuktas=True)\n","\n","  def add_word(self, word):\n","    if word not in self.word2index:\n","      self.word2index[word] = self.n_words\n","      self.word2count[word] = 1\n","      self.index2word[self.n_words] = word\n","      self.n_words += 1\n","\n","    else:\n","      self.word2count[word] += 1\n","\n","  def add_sentence(self, sentence):\n","    tokens = self.tokenize_sentence(sentence)\n","    for token in tokens: \n","      self.add_word(token)\n","\n","  def tokenize_sentence(self, sentence):\n","    # first normalize the sentence, then tokenize\n","    norm_sent = self.normalizer.normalize(sentence)\n","    tokens = indic_tokenize.trivial_tokenize(norm_sent)\n","    return tokens\n","\n","  def __len__(self):\n","    return self.n_words"]},{"cell_type":"markdown","metadata":{},"source":["## Building, saving and loading the vocabs"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T16:37:41.291948Z","iopub.status.busy":"2023-04-12T16:37:41.290759Z","iopub.status.idle":"2023-04-12T16:56:56.213635Z","shell.execute_reply":"2023-04-12T16:56:56.212352Z","shell.execute_reply.started":"2023-04-12T16:37:41.291904Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e8fe1562c5d4c519f66e58507e19ba0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/140000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["24261\n"]}],"source":["nlp_english = spacy.load(\"en_core_web_sm\")\n","english_output_vocab = Lang(\"english\", nlp_english)\n","\n","for my_sent in tqdm(output_sent_list):\n","  english_output_vocab.add_sentence(my_sent)\n","\n","print(len(english_output_vocab))\n","\n","#saving the english vocab\n","\n","with open('/kaggle/working/english_output_vocab.pkl', 'wb') as f: \n","  pickle.dump(english_output_vocab, f)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T16:36:57.287426Z","iopub.status.busy":"2023-04-12T16:36:57.286413Z","iopub.status.idle":"2023-04-12T16:37:05.596654Z","shell.execute_reply":"2023-04-12T16:37:05.595270Z","shell.execute_reply.started":"2023-04-12T16:36:57.287380Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e94eff89258b4e5995423b5c7620e1ec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/140000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["27939\n"]}],"source":["hindi_input_vocab = Hindi_lang(\"hindi\")\n","\n","for my_sent in tqdm(input_sent_list):\n","  hindi_input_vocab.add_sentence(my_sent)\n","\n","print(len(hindi_input_vocab))\n","\n","with open('/kaggle/working/hindi_input_vocab.pkl', 'wb') as f: \n","  pickle.dump(hindi_input_vocab, f)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:18.633473Z","iopub.status.busy":"2023-04-12T18:33:18.632974Z","iopub.status.idle":"2023-04-12T18:33:19.552648Z","shell.execute_reply":"2023-04-12T18:33:19.551591Z","shell.execute_reply.started":"2023-04-12T18:33:18.633426Z"},"trusted":true},"outputs":[],"source":["with open('/kaggle/input/somecs779/english_output_vocab.pkl', 'rb') as f:\n","    english_output_vocab = pickle.load(f)\n","    \n","with open('/kaggle/input/somecs779/hindi_input_vocab.pkl', 'rb') as f:\n","    hindi_input_vocab = pickle.load(f)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:22.382459Z","iopub.status.busy":"2023-04-12T18:33:22.382057Z","iopub.status.idle":"2023-04-12T18:33:22.389583Z","shell.execute_reply":"2023-04-12T18:33:22.388151Z","shell.execute_reply.started":"2023-04-12T18:33:22.382426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","1\n"]}],"source":["SOS_TOKEN_INDEX = english_output_vocab.word2index['<SOS>']\n","print(SOS_TOKEN_INDEX)\n","\n","EOS_TOKEN_INDEX = english_output_vocab.word2index['<EOS>']\n","print(EOS_TOKEN_INDEX)"]},{"cell_type":"markdown","metadata":{},"source":["## Preparing the data and making the Dataloader"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:25.027656Z","iopub.status.busy":"2023-04-12T18:33:25.026937Z","iopub.status.idle":"2023-04-12T18:33:25.032485Z","shell.execute_reply":"2023-04-12T18:33:25.031372Z","shell.execute_reply.started":"2023-04-12T18:33:25.027616Z"},"trusted":true},"outputs":[],"source":["MAX_LENGTH = 64 # this will be length of each sentence\n","BATCH_SIZE = 128"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:27.622559Z","iopub.status.busy":"2023-04-12T18:33:27.621867Z","iopub.status.idle":"2023-04-12T18:33:27.698020Z","shell.execute_reply":"2023-04-12T18:33:27.696721Z","shell.execute_reply.started":"2023-04-12T18:33:27.622523Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["140000\n","('और अपनी रहमत से हमें इन काफ़िर लोगों (के नीचे) से नजात दे', \"and deliver us by Thy mercy from the people of the unbelievers. '\")\n"]}],"source":["training_data = []\n","\n","for i in range(len(input_sent_list)):\n","  pair = (input_sent_list[i], output_sent_list[i])\n","  training_data.append(pair)\n","\n","print(len(training_data))\n","print(training_data[0])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:30.289287Z","iopub.status.busy":"2023-04-12T18:33:30.288900Z","iopub.status.idle":"2023-04-12T18:33:30.297100Z","shell.execute_reply":"2023-04-12T18:33:30.296001Z","shell.execute_reply.started":"2023-04-12T18:33:30.289252Z"},"trusted":true},"outputs":[],"source":["def tensorFromSentence(lang_vocab, sentence, max_length=MAX_LENGTH):\n","\n","  tokens = lang_vocab.tokenize_sentence(sentence)\n","  indexes = [lang_vocab.word2index[token] for token in tokens]\n","  indexes.append(EOS_TOKEN_INDEX)\n","\n","  pad_index = lang_vocab.word2index['<PAD>']\n","\n","  if len(indexes) < max_length:\n","    indexes += [pad_index] * (max_length - len(indexes))\n","  else:\n","    indexes = indexes[:max_length]\n","    indexes[-1] = EOS_TOKEN_INDEX\n","\n","  return torch.tensor(indexes, dtype=torch.long)\n","  # (max_length,)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:32.796280Z","iopub.status.busy":"2023-04-12T18:33:32.795503Z","iopub.status.idle":"2023-04-12T18:33:32.803146Z","shell.execute_reply":"2023-04-12T18:33:32.801813Z","shell.execute_reply.started":"2023-04-12T18:33:32.796232Z"},"trusted":true},"outputs":[],"source":["class Seq2SeqDataset(Dataset):\n","  \n","  def __init__(self, pairs):\n","    self.pairs = pairs\n","\n","  def __len__(self):\n","    return len(self.pairs)\n","\n","  def __getitem__(self, index):\n","    input_sentence, target_sentence = self.pairs[index]\n","    input_tensor = tensorFromSentence(hindi_input_vocab, input_sentence)\n","    target_tensor = tensorFromSentence(english_output_vocab, target_sentence)\n","    return input_tensor, target_tensor"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:34.895692Z","iopub.status.busy":"2023-04-12T18:33:34.894983Z","iopub.status.idle":"2023-04-12T18:33:34.900501Z","shell.execute_reply":"2023-04-12T18:33:34.899267Z","shell.execute_reply.started":"2023-04-12T18:33:34.895653Z"},"trusted":true},"outputs":[],"source":["dataset = Seq2SeqDataset(training_data)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:36.569328Z","iopub.status.busy":"2023-04-12T18:33:36.568371Z","iopub.status.idle":"2023-04-12T18:33:36.576233Z","shell.execute_reply":"2023-04-12T18:33:36.574843Z","shell.execute_reply.started":"2023-04-12T18:33:36.569275Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1094\n"]}],"source":["dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n","print(len(dataloader))"]},{"cell_type":"markdown","metadata":{},"source":["## Classes and functions required"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:42.686517Z","iopub.status.busy":"2023-04-12T18:33:42.685538Z","iopub.status.idle":"2023-04-12T18:33:42.695959Z","shell.execute_reply":"2023-04-12T18:33:42.694865Z","shell.execute_reply.started":"2023-04-12T18:33:42.686460Z"},"trusted":true},"outputs":[],"source":["class EncoderGRU(nn.Module):\n","\n","  def __init__(self, input_size, hidden_size, num_layers=1):\n","    super().__init__()\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.embedding = nn.Embedding(input_size, hidden_size)\n","    self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n","\n","  def forward(self, input_seqs, hidden):\n","\n","    # input_seqs.shape : (batch_size, )\n","\n","    embedded = self.embedding(input_seqs.unsqueeze(0))\n","    # embedded.shape = (1, batch_size, hidden_size)\n","\n","    output, hidden = self.gru(embedded, hidden)\n","    # output.shape = (1, batch_size, hidden_size) , (seq_len, batch_size, hidden_size)\n","    # hidde.shape = (num_layers, batch_size, hidden_size)\n","\n","    return output, hidden \n","\n","  def init_hidden(self, batch_size):\n","    hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size) # (num_layers, batch_size, hidden_dim)\n","    return hidden"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:44.211646Z","iopub.status.busy":"2023-04-12T18:33:44.211282Z","iopub.status.idle":"2023-04-12T18:33:44.219925Z","shell.execute_reply":"2023-04-12T18:33:44.218657Z","shell.execute_reply.started":"2023-04-12T18:33:44.211615Z"},"trusted":true},"outputs":[],"source":["class DecoderGRU(nn.Module):\n","\n","  def __init__(self, hidden_size, output_size, num_layers=1):\n","    super().__init__()\n","    self.hidden_size = hidden_size\n","    self.output_size = output_size\n","    self.num_layers = num_layers\n","    self.embedding = nn.Embedding(output_size, hidden_size)\n","    self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n","    self.out = nn.Linear(hidden_size, output_size)\n","\n","  def forward(self, input, hidden):\n","    # input shape = (batch_size, )\n","    output = self.embedding(input.unsqueeze(0)) # (1, batch_size, hidden_size)\n","    output = F.relu(output)\n","    output, hidden = self.gru(output, hidden) \n","    # output : (1, batch_size, hidden_size)\n","    # hidden : (num_layers, batch_size, hidden_size)\n","    output = self.out(output[0]) # (batch_size, output_size)\n","    return output, hidden\n","\n","  def init_hidden(self, batch_size):\n","    hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size) # (num_layers, batch_size, hidden_size)\n","    return hidden"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:45.760630Z","iopub.status.busy":"2023-04-12T18:33:45.760274Z","iopub.status.idle":"2023-04-12T18:33:45.773035Z","shell.execute_reply":"2023-04-12T18:33:45.771756Z","shell.execute_reply.started":"2023-04-12T18:33:45.760600Z"},"trusted":true},"outputs":[],"source":["def train(input_tensors: torch.Tensor,\n","          target_tensors: torch.Tensor,\n","          encoder: EncoderGRU,\n","          decoder: DecoderGRU,\n","          encoder_optimizer, decoder_optimizer, criterion, teacher_forcing_ratio=0.5):\n","  \n","  # input_tensors.shape = (batch_size, max_length)\n","  # Target_tensors.shape = (batch_size, max_length)\n","\n","  batch_size = input_tensors.size(0)\n","\n","  input_tensors = input_tensors.transpose(0, 1).to(device) # transpose to (max_len, batch_size), then push to device\n","  target_tensors = target_tensors.transpose(0, 1).to(device) # transpose to (max_len, batch_size), then push to device\n","\n","  encoder_optimizer.zero_grad()\n","  decoder_optimizer.zero_grad()\n","\n","  encoder_hidden = encoder.init_hidden(batch_size).to(device)\n","  encoder_outputs = torch.zeros(MAX_LENGTH, batch_size, encoder.hidden_size).to(device)\n","\n","  loss = 0\n","\n","  for ei in range(MAX_LENGTH):\n","    encoder_output, encoder_hidden = encoder(input_tensors[ei], encoder_hidden) \n","    # encoder is taking input of shape of (batch_size, )\n","    encoder_outputs[ei] = encoder_output[0, :, :]\n","\n","\n","  decoder_input = torch.tensor([SOS_TOKEN_INDEX] * batch_size, device=device, dtype=torch.long)\n","  decoder_hidden = encoder_hidden\n","\n","  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","  if use_teacher_forcing:\n","\n","    # feed the target as the next input\n","    for di in range(MAX_LENGTH): \n","      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","      loss += criterion(decoder_output, target_tensors[di])\n","      decoder_input = target_tensors[di]\n","\n","  else:\n","\n","    # without teacher forcing: use it's own predictions as input in the next step\n","    for di in range(MAX_LENGTH):\n","      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","      # decoder_output : (batch_size, output_size)\n","      topv, topi = decoder_output.topk(k=1) \n","\n","      # topv, topi : (batch_size, 1)\n","\n","      decoder_input = topi.detach().squeeze(-1) # decoder needs 1d input of shape (batch_size, )\n","      loss += criterion(decoder_output, target_tensors[di])\n","\n","      if (decoder_input == EOS_TOKEN_INDEX).all():\n","        break\n","\n","  loss.backward()\n","\n","  encoder_optimizer.step()\n","  decoder_optimizer.step()\n","\n","  ans = loss.detach().cpu().item()/MAX_LENGTH\n","  return ans"]},{"cell_type":"markdown","metadata":{},"source":["## Actual code"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:33:48.331891Z","iopub.status.busy":"2023-04-12T18:33:48.331526Z","iopub.status.idle":"2023-04-12T18:33:48.336924Z","shell.execute_reply":"2023-04-12T18:33:48.335782Z","shell.execute_reply.started":"2023-04-12T18:33:48.331852Z"},"trusted":true},"outputs":[],"source":["hidden_size = 100\n","learning_rate = 0.001\n","max_epochs = 10\n","num_layers = 6"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:35:04.979614Z","iopub.status.busy":"2023-04-12T18:35:04.979226Z","iopub.status.idle":"2023-04-12T18:35:05.819493Z","shell.execute_reply":"2023-04-12T18:35:05.817559Z","shell.execute_reply.started":"2023-04-12T18:35:04.979581Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["EncoderGRU(\n","  (embedding): Embedding(27939, 100)\n","  (gru): GRU(100, 100, num_layers=6)\n",")\n","DecoderGRU(\n","  (embedding): Embedding(24261, 100)\n","  (gru): GRU(100, 100, num_layers=6)\n","  (out): Linear(in_features=100, out_features=24261, bias=True)\n",")\n"]}],"source":["encoder = EncoderGRU(len(hindi_input_vocab), hidden_size, num_layers).to(device)\n","decoder = DecoderGRU(hidden_size, len(english_output_vocab), num_layers).to(device)\n","\n","encoder.load_state_dict(torch.load('/kaggle/input/somecs779/encoder.params'))\n","decoder.load_state_dict(torch.load('/kaggle/input/somecs779/decoder.params'))\n","\n","print(encoder)\n","print(decoder)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T18:35:25.868524Z","iopub.status.busy":"2023-04-12T18:35:25.867828Z","iopub.status.idle":"2023-04-12T22:30:15.949985Z","shell.execute_reply":"2023-04-12T22:30:15.949070Z","shell.execute_reply.started":"2023-04-12T18:35:25.868485Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9e0c4c6bf604f26aceea93d6361f04e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"055aa5d62b314233b0b25f7dafc225a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1094 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch = 0/10, LOSS = 1.7596835223804663\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6aec49835f2a4444a9ecf06b0f015055","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1094 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch = 1/10, LOSS = 1.659582788809126\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e409ba2f6d647fbac81c744430dd945","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1094 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch = 2/10, LOSS = 1.605336882732468\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a0ebcf8d0c8409cbbcb0b3454a2a009","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1094 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch = 3/10, LOSS = 1.5629786416425129\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4baa5877d704afa90ae46909fc5bd3a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1094 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch = 4/10, LOSS = 1.5289457392431047\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2133d35dcf7045ada366bd1b607e5e79","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1094 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch = 5/10, LOSS = 1.4780008552606188\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e35b0a915d745f8bd3e78ba8be72ca8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1094 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch = 6/10, LOSS = 1.4660549174170172\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95a44723dce44777a46f12b221ea6da8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1094 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch = 7/10, LOSS = 1.4271439889231374\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc42d948e9604aa49da2883eb00e14f3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1094 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch = 8/10, LOSS = 1.4103795755824833\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39406fbdd65d4568b81df5f7c720d326","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1094 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch = 9/10, LOSS = 1.3730219078456245\n"]}],"source":["for epoch in tqdm(range(max_epochs)):\n","\n","  epoch_loss = 0\n","\n","  for batch in tqdm(dataloader):\n","\n","    input_tensors = batch[0].to(device)\n","    target_tensors = batch[1].to(device)\n","\n","    loss = train(input_tensors, target_tensors, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","\n","    epoch_loss += loss\n","\n","  print(f\"epoch = {epoch}/{max_epochs}, LOSS = {epoch_loss/len(dataloader)}\")\n","\n","  with open('/kaggle/working/training_loss.txt', \"a\") as f: \n","        my_dict = {\"epoch\": epoch, \"max_epochs\": max_epochs, \"epoch_loss\": epoch_loss/len(dataloader)}\n","        f.write(f\"{my_dict}\\n\")\n","\n","  torch.save(encoder.state_dict(), '/kaggle/working/encoder.params')\n","  torch.save(decoder.state_dict(), '/kaggle/working/decoder.params')"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:14:51.533075Z","iopub.status.busy":"2023-04-12T23:14:51.532258Z","iopub.status.idle":"2023-04-12T23:14:51.583591Z","shell.execute_reply":"2023-04-12T23:14:51.582267Z","shell.execute_reply.started":"2023-04-12T23:14:51.533040Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DecoderGRU(\n","  (embedding): Embedding(24261, 100)\n","  (gru): GRU(100, 100, num_layers=6)\n","  (out): Linear(in_features=100, out_features=24261, bias=True)\n",")"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["encoder.cpu()\n","encoder.eval()\n","\n","decoder.eval()\n","decoder.cpu()"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:16:36.351989Z","iopub.status.busy":"2023-04-12T23:16:36.351281Z","iopub.status.idle":"2023-04-12T23:16:36.359648Z","shell.execute_reply":"2023-04-12T23:16:36.358358Z","shell.execute_reply.started":"2023-04-12T23:16:36.351954Z"},"trusted":true},"outputs":[],"source":["def tensorFromSentenceEval(lang_vocab, sent, max_length=MAX_LENGTH):\n","    \n","    tokens = lang_vocab.tokenize_sentence(sent)\n","    existing_tokens = lang_vocab.word2index.keys()\n","    \n","    indexes = []\n","    for token in tokens:\n","        if token in existing_tokens:\n","            index = lang_vocab.word2index[token] \n","        else:\n","            index = lang_vocab.word2index['<UNK>']\n","        indexes.append(index)\n","\n","    pad_index = lang_vocab.word2index['<PAD>']\n","\n","    if len(indexes) < max_length:\n","        indexes += [pad_index] * (max_length - len(indexes))\n","\n","    else:\n","        indexes = indexes[:max_length]\n","\n","    return torch.tensor(indexes, dtype=torch.long)\n","    # (max_length,)"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:25:47.794861Z","iopub.status.busy":"2023-04-12T23:25:47.794390Z","iopub.status.idle":"2023-04-12T23:25:47.805552Z","shell.execute_reply":"2023-04-12T23:25:47.804237Z","shell.execute_reply.started":"2023-04-12T23:25:47.794819Z"},"trusted":true},"outputs":[],"source":["class Test_Set(Dataset):\n","    \n","    def __init__(self, test_sentences_list):\n","        self.sent_list = test_sentences_list\n","        \n","    def __len__(self):\n","        return len(self.sent_list)\n","    \n","    def __getitem__(self, index):\n","        input_sentence = self.sent_list[index]\n","        input_tensor = tensorFromSentenceEval(hindi_input_vocab, input_sentence)\n","        return input_tensor"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:44:44.039346Z","iopub.status.busy":"2023-04-12T23:44:44.038953Z","iopub.status.idle":"2023-04-12T23:44:44.048959Z","shell.execute_reply":"2023-04-12T23:44:44.047684Z","shell.execute_reply.started":"2023-04-12T23:44:44.039313Z"},"trusted":true},"outputs":[],"source":["def evaluate(encoder, decoder, input_tensors, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        \n","        batch_size = input_tensors.size(1)    \n","        \n","        # Initialize the encoder hidden state\n","        encoder_hidden = encoder.init_hidden(batch_size)\n","        \n","        for i in range(max_length):\n","            _, encoder_hidden = encoder(input_tensors[i], encoder_hidden)\n","\n","        # Initialize the decoder input as a tensor of SOS tokens\n","        decoder_input = torch.tensor([SOS_TOKEN_INDEX] * batch_size, dtype=torch.long)\n","\n","        # Initialize the decoder hidden state with the final hidden state of the encoder\n","        decoder_hidden = encoder_hidden\n","\n","        # Initialize the decoded output sequence as a list of empty tensors\n","        decoded_outputs = [torch.tensor([], dtype=torch.long)] * batch_size\n","\n","        # Loop over each time step in the output sequence\n","        for timestep in range(max_length):\n","            # Pass the decoder input and hidden state through the decoder\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","\n","            # Choose the token with the highest score as the next input to the decoder\n","            _, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze(-1).detach()\n","\n","            # Concatenate the decoded output tensor for this time step to the decoded_outputs list\n","            for i in range(batch_size):\n","                decoded_outputs[i] = torch.cat((decoded_outputs[i], topi[i].unsqueeze(0)))\n","\n","        # Return the decoded output sequences as a tensor of shape (max_length, batch_size)\n","        return torch.stack(decoded_outputs).transpose(0, 1)\n"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:45:08.017328Z","iopub.status.busy":"2023-04-12T23:45:08.016714Z","iopub.status.idle":"2023-04-12T23:45:08.023292Z","shell.execute_reply":"2023-04-12T23:45:08.022121Z","shell.execute_reply.started":"2023-04-12T23:45:08.017278Z"},"trusted":true},"outputs":[],"source":["def IndexesToSent(indexes, output_vocab):\n","    \n","    words = []\n","    for idx in indexes:\n","        if idx == EOS_TOKEN_INDEX:\n","            break\n","        if idx != output_vocab.word2index['<PAD>']:\n","            words.append(output_vocab.index2word[idx])\n","            \n","    return ' '.join(words)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:16:39.341312Z","iopub.status.busy":"2023-04-12T23:16:39.340095Z","iopub.status.idle":"2023-04-12T23:16:39.469840Z","shell.execute_reply":"2023-04-12T23:16:39.468789Z","shell.execute_reply.started":"2023-04-12T23:16:39.341267Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(40000, 1)\n"]}],"source":["test_set = pd.read_csv(\"/kaggle/input/mt-dev-set/eng_Hindi_data_dev_X.csv\", header=None)\n","print(test_set.shape)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:13:44.933130Z","iopub.status.busy":"2023-04-12T23:13:44.930528Z","iopub.status.idle":"2023-04-12T23:13:44.957884Z","shell.execute_reply":"2023-04-12T23:13:44.956807Z","shell.execute_reply.started":"2023-04-12T23:13:44.933072Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>और अनुसर्ण करो उस सर्वोत्तम चीज़ का जो तुम्हार...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>एक क़ाफ़िला आया। फिर उसने पनिहारा को भेजा। उसन...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>जो कोई सुचरित लेकर आया उसको उससे भी अच्छा प्रा...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>raviratlami @aol. inEMAIL OF TRANSLATORS</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>घटना/कार्य/बैठक संपादक में RSVP क्षेत्र दिखायें</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   0\n","0  और अनुसर्ण करो उस सर्वोत्तम चीज़ का जो तुम्हार...\n","1  एक क़ाफ़िला आया। फिर उसने पनिहारा को भेजा। उसन...\n","2  जो कोई सुचरित लेकर आया उसको उससे भी अच्छा प्रा...\n","3           raviratlami @aol. inEMAIL OF TRANSLATORS\n","4    घटना/कार्य/बैठक संपादक में RSVP क्षेत्र दिखायें"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["test_set.head()"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:14:15.908626Z","iopub.status.busy":"2023-04-12T23:14:15.907685Z","iopub.status.idle":"2023-04-12T23:14:15.917126Z","shell.execute_reply":"2023-04-12T23:14:15.914581Z","shell.execute_reply.started":"2023-04-12T23:14:15.908587Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'>\n","40000\n"]}],"source":["test_sentences = test_set.iloc[:, 0].tolist()\n","print(type(test_sentences))\n","print(len(test_sentences))"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:44:50.305891Z","iopub.status.busy":"2023-04-12T23:44:50.305534Z","iopub.status.idle":"2023-04-12T23:44:50.311065Z","shell.execute_reply":"2023-04-12T23:44:50.309730Z","shell.execute_reply.started":"2023-04-12T23:44:50.305860Z"},"trusted":true},"outputs":[],"source":["test_dataset = Test_Set(test_sentences)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:27:55.669098Z","iopub.status.busy":"2023-04-12T23:27:55.668739Z","iopub.status.idle":"2023-04-12T23:27:55.687520Z","shell.execute_reply":"2023-04-12T23:27:55.686152Z","shell.execute_reply.started":"2023-04-12T23:27:55.669068Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'torch.Tensor'>\n","torch.Size([128, 64])\n"]}],"source":["batch = next(iter(test_loader))\n","print(type(batch))\n","print(batch.shape)"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:45:11.691813Z","iopub.status.busy":"2023-04-12T23:45:11.691082Z","iopub.status.idle":"2023-04-12T23:52:53.713354Z","shell.execute_reply":"2023-04-12T23:52:53.712278Z","shell.execute_reply.started":"2023-04-12T23:45:11.691776Z"},"trusted":true},"outputs":[],"source":["output_list = []\n","\n","for batch in tqdm(test_loader):\n","    \n","    temp = evaluate(encoder, decoder, batch.transpose(0, 1)).squeeze()\n","    \n","    for sent in temp:\n","        index_list = sent.tolist()\n","        conv_sent = IndexesToSent(index_list, english_output_vocab)\n","        output_list.append(conv_sent)"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:53:00.975932Z","iopub.status.busy":"2023-04-12T23:53:00.975557Z","iopub.status.idle":"2023-04-12T23:53:00.981720Z","shell.execute_reply":"2023-04-12T23:53:00.980552Z","shell.execute_reply.started":"2023-04-12T23:53:00.975900Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['and and whoever % show and he these then then invalid evolution & save to disable say move he open is save % the and and the could say the light there \" \" st and say and error i or set unable can \" toggles they or construct it and say click the _ unable failed the the you select and the the and can is allah audio how do but and click and they show and they so _ disc this then you move he the they _ and if and use in odessa and and then it % and start error say comma no they he the those kde they but and % use does and select error this except click it and show they', 'the the will 1 the is said are we they opaque invitations & project allah use : tab said in he the s is the many is not , revelation rain is allah i _ when : when server thou they here to not o whether they they a is the : here the s to to quot the can the we good display we not he has disc many you those i here when they the it have lord _ disc is he can tab said is call save the you those the the is they the he is s those this while , style our have is unbelievers who - said the the s:% the he the the error is to the is they the said', 'the the the square field the , the have said trace to custom to belongs message \" _ : new can data is is day many is connect “ of fog not is is op the “ our code% not they the open find our not swear they cogl revealed women \\' to the 1 add open quot of to text gave women of have not that sent ( the not who i to it they buttons will not , verride ( been turned to _ , the to folder the choose who , couches a will will he not ( who to loading “ ( lord no he say disbelieve plugin , soul patient s:% when create night point occurred the the current he not sender :', 'of the of square field is “ people them : information:% connect text add the threads i width \" mail not to free the when of is to i the fog no the no animation sky i verses s the not methods file signing son not to not for to is the show the _ a document ; the to text the is the we a , the % generation that deny that be said them in not not and address % meeting to to left “ the them folder the to who and will a their will the the % who to the my to is intercessors who : who plugin ‘ will will s mail a night of while god the image who the of \"', 'of the of']\n"]}],"source":["print(output_list[:5])"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:56:13.986187Z","iopub.status.busy":"2023-04-12T23:56:13.985606Z","iopub.status.idle":"2023-04-12T23:56:13.991902Z","shell.execute_reply":"2023-04-12T23:56:13.990827Z","shell.execute_reply.started":"2023-04-12T23:56:13.986150Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["print(output_list[-1])"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:56:36.746273Z","iopub.status.busy":"2023-04-12T23:56:36.745891Z","iopub.status.idle":"2023-04-12T23:56:36.776836Z","shell.execute_reply":"2023-04-12T23:56:36.775883Z","shell.execute_reply.started":"2023-04-12T23:56:36.746240Z"},"trusted":true},"outputs":[],"source":["with open('/kaggle/working/answer.txt', \"a\") as f: \n","    for out in output_list:\n","        f.write(f\"{out.encode('utf-8')}\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["# Random"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:35:07.536894Z","iopub.status.busy":"2023-04-12T23:35:07.536297Z","iopub.status.idle":"2023-04-12T23:35:07.542871Z","shell.execute_reply":"2023-04-12T23:35:07.541744Z","shell.execute_reply.started":"2023-04-12T23:35:07.536857Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[tensor([], dtype=torch.int64), tensor([], dtype=torch.int64), tensor([], dtype=torch.int64)]\n"]}],"source":["a = [torch.tensor([], dtype=torch.long)] * 3\n","print(a)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T22:50:32.554846Z","iopub.status.busy":"2023-04-12T22:50:32.554483Z","iopub.status.idle":"2023-04-12T22:50:32.561242Z","shell.execute_reply":"2023-04-12T22:50:32.559932Z","shell.execute_reply.started":"2023-04-12T22:50:32.554814Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["no\n"]}],"source":["a = {1: \"hell\", 2: \"bye\"}\n","b = 'gandu'\n","\n","if b in a.values():\n","    print(\"yes\")\n","else:\n","    print(\"no\")"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T23:43:57.830182Z","iopub.status.busy":"2023-04-12T23:43:57.829621Z","iopub.status.idle":"2023-04-12T23:43:57.837431Z","shell.execute_reply":"2023-04-12T23:43:57.836334Z","shell.execute_reply.started":"2023-04-12T23:43:57.830146Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.22617703676223755, 0.4085897207260132, 0.9911841154098511, 0.33149629831314087]\n","[0.05995970964431763, 0.7917261123657227, 0.5551609992980957, 0.08077502250671387]\n","[0.11251026391983032, 0.07683908939361572, 0.26595205068588257, 0.06419819593429565]\n"]}],"source":["a = torch.rand(3, 4)\n","\n","for i in a:\n","    print(i.tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
